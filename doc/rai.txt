RAI - Racket Abstract Interpretation

Development log for the RAI project.

The goal of this project is to explore code generation and validation
using techniques based on Abstract Interpretation, implemented in
Racket.

For more information, visit http://zwizwa.be/rai

This log was forked from:
http://zwizwa.be/-/meta
which contains more information about the Haskell leg of the project.


Entry: Move to git / github / racket package
Date: Sun Jun  2 19:13:02 EDT 2013

Starting on a fresh repo.

http://zwizwa.be/rai

raco pkg install github://github.com/zwizwa/rai/master

parent dev log:     http://zwizwa.be/-/meta
parent darcs repo:  http://zwizwa.be/darcs/meta


Entry: TODO
Date: Sun Jun  2 19:14:08 EDT 2013


Maybe good to make a list of the small things that need to be done.

- FIXES:

  - ai-stream.rkt   (write in terms of ai-array.rkt output?)

  - delay line allocation: phase 1 -> phase 2.

  - make time block explicit (subsampling) and fixed size

  - proper feedback operator

  - compute transfer function as ratfunc.


- FEATURES:

  - constant arrays.

  - presets

  - state initialization

  - generate GUI from description

  - loop fusion? (check out Feldspar)




Entry: Add a `where' form?
Date: Sun Jun  2 19:27:46 EDT 2013

This would allow specification of inputs/outputs in a more
straightforward way, such that output arity is visible at the syntax
level.

E.g.

(proc (in ...)
      (out ...)
  (where
     ((a ...)
      (b ...)
      ...)))



Entry: Run generated C code from Scheme
Date: Mon Jun  3 19:48:43 EDT 2013

3 ways to run code in Scheme:

- provide separate interpretation, like ai-stream.rkt (reference implementation)
- compile the pre-C imperative intermediate language to Scheme
- load a compiled C module




Entry: John Clements Course
Date: Mon Jun 10 07:57:55 EDT 2013


http://www.brinckerhoff.org/JBCsite/index.html
http://www.brinckerhoff.org/clements/
http://www.brinckerhoff.org/clements/csc123-fa12/index.html




Entry: Next
Date: Mon Jun 10 08:08:37 EDT 2013

Low on time and energy.  What needs to happen next?


- LLVM C/C++ bindings

- Load C code in Scheme

- Scheme semantics based on ai-array form output



Entry: KVR post
Date: Tue Jun 11 08:43:08 EDT 2013

http://www.kvraudio.com/forum/viewtopic.php?p=5385673#5385673

Hi Frank,

What I find most interesting in language design is the basic
principles or "axioms", being
1) primitive operations, and
2) composition/abstraction mechanisms to build new operations

IIUC, your patch language is functional, except for the primitives,
which have state.  Some questions about the composition mechanism:

- How do you differentiate between "class" and "instance" for the
  primitives?  I.e. there is Osc1 and Osc2.  Are these fixed
  instances of a shared oscillator class?

- Is there an abstraction mechanism?  I.e. is there a way to take a
  couple of modules and create a new black box to be used in another
  patch?

Cheers
Tom


Entry: Pd-dev, music-dsp, racket list post
Date: Wed Jun 12 11:28:54 EDT 2013



Hi List,

I've been cleaning it up a bit. Still quite raw in the details, but it basically works.

added synth-lib.rkt basic synth kit and synth.rkt example synthesizer:

- envelopes
- parameter control dezippers
- parameter control scales (exponential, "squashed" exponential, ...)
- SVF filter
- supersaw osc
- anti-aliased saw osc
- saturation functions
- FDN reverb tail

How I use it at this time, Linux + Pd:

make sp_host.pd_linux # build binary Pd wrapper
pd sp_test.pd & # run Pd patch built around sp_host
make livecode # continuously compile synth.rkt -> synth.sp binary module

then edit synth.rkt or any of its dependencies and the binary code running in Pd will be updated, leaving state intact if the type didn't change.

some docs at http://zwizwa.be/rai


For headless Windows VST plugin:  "make synth.dll"
This needs a Linux->Windows cross compiler; follow the error messages.

Cheers
Tom



Entry: LLVM?
Date: Wed Jun 12 13:28:34 EDT 2013

Maybe an LLVM target would be a nice addition.  Running code in-image
without external C compiler dependencies is attractive, though is it
worth the trouble?



Entry: Industry integration: validated, bottom-up design
Date: Wed Jun 12 13:46:55 EDT 2013

I'd like to be able to integrate what I've learned up to now (the
knowledge that lead to RAI) and steer it more into a direction that is
usable in an industrial setting.

At this point it is usable for designing music DSP software on PCs or
mobile devices, but not yet so usable for machine mapping as would be
encountered in a typical embedded development settings, i.e. the
projects that pay the bills.

One important element is target dependency.  It might make more sense
to construct a tool that helps manual machine mapping of an existing
algorithm, than to attempt to work top-down as I'm doing for the synth
work.

At least for code running on a quirky DSP chip there is going to be a
significant amount of squeezing involved to map to a particular
target.  It doesn't seem that the trend of quirky hardware is not
going to change much in the near future, as power consumption and
device cost constraints will keep much of the manual design approach
alive.

For the big guys, there are plenty of expensive tools available.  Have
a look at the MathWorks product range.  More, bigger tools can be
found in the ASIC industry.  For the small guys doing one-off jobs,
these tools just too expensive.  What I've been wondering for 10 years
is how far can one get with open tools to make the lone wolf embedded
developer more productive?

I want to stress this: none of the ideas here are new.
What is new is to keep it simple, small and malleable.

A large constraint in reality is the introduction of exotic tool
chains.  My conclusion is that people hate it: it's too big a risk to
use yet another quirky code generator whenever a new person joins the
team.  A big constraint for designing tools is to make sure they can
get out of the way, i.e. that you can switch them OFF and drop down to
writing straight ASM or C code.

In a nutshell: VALIDATION of a low-level implementation is more
important than GENERATION from high to low level.

In practice, in the RAI framework, this would boil down to finding a
set of primitives, probably based on the machine's primitive, AND a
set of machine constraints and resource management annotations.

This is not a simple problem.  To keep it simple, a most
straightforward approach is to start with a reduced assembler
language, and see how to put a functional semantics on top of that.


So what about this for future direction:

  - Aiming at validation, use the abstract interpretation trick to
    approximate the semantics of a real device.

  - Pick a target to test this: dsPIC or ARM DSP / Cortex M4



Entry: What target to pick?
Date: Wed Jun 12 13:57:31 EDT 2013

dsPIC:

+ combined with PIC18 support in Staapl, I could aim at 1 vendor
  (Microchip) / 1 tool (Racket) approach.

+ DIP available, good for grassroots electronics projects

- typical quirky DSP arch with lots of constraints

- no free optimizing C compiler for both PIC18 and dsPIC.



ARM Cortex M4 [1]

+ industry standard, multiple vendors: TI Stellaris, STM32 F3,F4

+ good open tooling support

+ plenty of boards

- no DIP available



[1] http://en.wikipedia.org/wiki/ARM_Cortex-M#Cortex-M4



Entry: Idiomatic C
Date: Wed Jun 12 14:50:53 EDT 2013

It would be interesting to find the subset of C that can accomodate
the basic stream language's semantics.



Entry: Merging ideas: Staapl and RAI
Date: Wed Jun 12 16:53:54 EDT 2013

Both have an element of bottom-up design, but for RAI, the bottom is a
small, well-defined language, while for Staapl, bottom is the machine
language.

Making this work for Staapl was one of the goals, but has not been
reached yet.

I wonder where the middle ground is here: design a machine abstraction
close enough to the real machine to allow for hand-tuned allocation,
and high level enough to have a decent semantics.

Another thing is to properly gauge the importance of resource
efficiency vs. safety/correctness.  If resource efficiency is not a
main driver, code gen might be a better option.



Entry: Project management: future of RAI
Date: Thu Jun 13 09:53:11 EDT 2013

After about 5 months the goals are reached.  RAI is good enough for
its initial intended purpose.  The rest seems to be "long tail"
maintenance, refinement, cleanup and gaining more insight through
concrete use cases.

I find myself in a bit of an impasse at this point, as the strongly
mobilizing curiosity is no longer there.

Maybe it is important at this point to realize that, and keep what
there is now as a stable core.  I.e. build extensions as external
projects.




Entry: A simplified simulator
Date: Thu Jun 13 14:36:57 EDT 2013

Problem: find a good approximation to a chip's instruction set that
can be embedded in a functional language.

This attempts to connect two worlds:
  - Easy translation to "real" device semantics
  - Easy translation from pure functional constructs

The problem here is resource management.

For the particular problem of simplifying the dsPIC, this would be to
abstract X/Y data memory, accumulator and addressing modes.






Entry: Composing state machines
Date: Fri Jun 14 10:06:26 EDT 2013


Note these are synchronous state machines, which are a bit simpler
than event-based ones.  The basic model I use for the audio DSP work
is the state space model (SSM) or state space representation, which
has nice properties if it is linear:

http://en.wikipedia.org/wiki/State_space_representation

Goal: represent a stream operator in Haskell in an abstract way, but
allow for C code generation from the description.

A stream operator consists of an initial state value and update
function with types:

s
(s,i) -> (s,o)

Ignoring the explicit state, the straightforward way to represent a
stream operator as a pure function is something like this:

    data S a = S a (S a)
    S i -> S o

However, the state info is lost here.  So the SSM rep can be mapped to
the stream rep, but not vice versa.


When composing two SSMs (ignoring the initial state) you get something
like:

   ( (s1,a) -> (s1,b) ) ->
   ( (s2,b) -> (s2,c) ) ->
   ((s1,s2),a) -> ((s1,s2), c)

This is troublesome, because the state "grows".

The whole thing is here:
http://zwizwa.be/darcs/meta/dspm/SSM.hs


The composition would fit neatly in the Arrow abstraction except for
that dangling state vector.

It is possible to use existential types to hide the states.
The trouble with that is they become quite inaccessible.

In the end, after composition, I really want a type (s,i) -> (s,o)
where s is a large composition of per-SSM state vectors, because that
information is used to generate C code.  I also want this to fit in
the Arrow abstraction, so it integrates better into Haskell.

For code generation, the SSM idea is combined with the "final tagless"
representation trick to perform abstract interpretation.  See:

http://zwizwa.be/darcs/meta/dspm/Control.hs
http://zwizwa.be/darcs/meta/dspm/Data.hs
http://zwizwa.be/darcs/meta/dspm/Struct.hs

All this +- works.  To work out how exactly to use the existential
types, I did some type directed programming to just see where the
types lead me, but in the end I got confused.  It all seems a bit
clumsy.

I took that idea and went back to Scheme (Racket) to do what I wanted
to do in the first place; to build a tool that I can use effectively
to write audio DSP code (*).  This is the result up to now:
http://zwizwa.be/rai/

Doing it in Scheme allowed me to "emulate" types and type classes.  An
interesting exercise in itself, but still, in Haskell it would be a
lot simpler.

Now that I know that the basic idea works, I'd like find a good way to
port it back to Haskell, probably on top of Feldspar.
http://hackage.haskell.org/package/feldspar-language



Entry: Fluxus / LLVM / Pd
Date: Mon Jun 17 10:53:31 EDT 2013

So, what's next?  A big fork in the road:

- Target "real" DSPs, i.e. TI C2000, MicroChip dsPIC, ...

- Integrate into host tools like Pd, Fluxus, ...

Former seems a bit far off at this point.  It would be great to have a
real project drive this.  Hybrid analog synth based on dsPIC?  
I ordered a C2000 eval board, which might lead to an interesting avenue.


For the latter, it would still be possible to use an external .c to
.so compilation step, but it is really awkward.  It might be a lot
better to bite the bullet and go for a JITtable LLVM approach.

The question is where to make the Scheme <-> C bridge for the LLVM
bindings.  As I understand, C++ isn't so easy from Racket FFI[1].




[1] https://groups.google.com/forum/?fromgroups#!topic/racket-users/GFrGBbczTc0



Entry: Fluxus install
Date: Mon Jun 17 11:11:12 EDT 2013

Probably best to just follow instructions and install to /usr/local

* Racket from git

git clone git://git.racket-lang.org/plt
cd plt
./configure --enable-shared --prefix=/usr/local
make
sudo make install


* Fluxus from git

git clone git://git.savannah.nongnu.org/fluxus.git
cd fluxus
scons

NOTE: I could not get this to work without symlinking bin & lib &
include from the git-racket tree into /usr/local



Entry: Live coding
Date: Mon Jun 17 16:49:40 EDT 2013

Back to the life coding idea.  I want to stick to the Scheme approach:
language works better than graphical programming, but I also want Bret
Victor's number boxes[1], essentially Pd's number boxes in code.

I wonder if this is possible in Fluxus.

[1] http://worrydream.com/#!/InventingOnPrinciple


Entry: Fluxus question
Date: Mon Jun 17 16:56:07 EDT 2013


fluxus@lists.pawfal.org


Hi List,

I recently saw Brent Victor's "Inventing On Principle"
http://worrydream.com/#!/InventingOnPrinciple

How hard would it be to make those "number sliders" work in Fluxus?
That is, if it's not already possible..

Basically, hover over a number in the editor and allow the mouse to change its range.

Cheers
Tom



Entry: Cortex-M4F
Date: Sat Aug 24 15:40:51 EDT 2013

Got the Tiva Launchpad[1] with a TM4C123GH6PMI[2].

Goal: write DSP library code for the Cortex-M4 DSP and/or FP.

It would be nice to be able to attach it to some audio codec, though
for now it seems simplest to just use a USB audio interface to patch
it into a test system.

TI Tivaware can be used for dev dependency, since I won't need to
redistribute anything.  People that need to reproduce the dev env can
just download SW-TM4C-1.1.exe themselves.  This probably also means I
can use


Roadmap:
- toolset setup
- get bare-bones DSP code running in RAM / Flash
- USB audio interface for testing (using tivaware)
- Some HW codec? Old soundcard patch? Sparkfun[3]? PWM? software S/D?


[1] http://www.ti.com/tool/ek-tm4c123gxl
[2] http://www.ti.com/product/tm4c123gh6pm
[3] https://www.sparkfun.com/products/9365


Entry: MinGW
Date: Sun Aug 25 00:19:11 EDT 2013

So it builds on cygwin using cygwin-hosted MinGW, and stand-alone
MinGW.  However, the build scripts use shell commands.



Entry: Live coding
Date: Mon Sep  2 12:50:07 EDT 2013

Time to think about user interfaces.  I'd like to implement a feature
from Bret Victor's talk[1], where constants embedded in code can have
a pop-up slider to change the value, with the result changing
immediately.

While this slider thing is neat, what is really important is a fast
update between editor save and audible effect., i.e. a very fast
compilation cycle for tick() methods.  The C compiler probably needs
to be removed from the loop, and possibly, all optimization could be
switched off: code could run interpreted at first.

The bottleneck is the speed at wich the partial evaluation runs.
Let's try to benchmark this first.  After that, an interpreted
mechanism could be built for the C-like language.

For (time (reload)) in this I get about 1.0 - 1.3 seconds:

  #lang racket/base
  (require "ai-array-c.rkt")

  (provide (all-defined-out))

  (define (reload)
    (define ns (make-base-namespace))
    (eval `(begin
             (require "ai-array-c.rkt")
             (require (file "synth.rkt"))
             (display (ai-array-c main #:nsi main-nsi)))
          ns))

About half the time is spent in the Scheme compilation phase.
Re-running the AI interpretation step gives:

(time (void (ai-array-c main #:nsi main-nsi))) ;; => 0.7 sec


This seems like a lot.  Trouble might be in the symbol lookup.  Hashes
could make things faster, maybe.  But improving the Scheme compilation
time isn't something I see happening, so it might nog be worth the
bother.

Adding the C compiler to this is fast if optimizations are turned off.

To get better performance, the problem should be tackled somewhere
else: compile to a more dynamic structure, and modify that stucture's
parameters instead of recompiling everything.


[1] http://www.youtube.com/watch?v=PUv66718DII#t=496


Entry: gdb & gcc/as
Date: Sun Sep 15 17:12:50 EDT 2013

Got basics for gcc/as compilation and gdb interaction working.  The
idea is to make some kind of "console" where asm code can be tested
interactively, either on real hardware or in the qemu emulator.

I started getting into brainless hack mode trying to parse the gdb
output.  Looks like some emacs code uses a regexp massager to
translate the format to json, and then uses a json parser[1].

I do wonder, for a syntax as simple as that, there has to be a nice
racket tool that can do it.  E.g. a packrat parser..

EDIT: It wasn't so hard to write a recursive descent parser using
`peek-char' and `read-char'.


[1] https://github.com/dov/dov-env/blob/master/emacs/gdb-mi.el



Entry: qemu emulator
Date: Sun Sep 15 17:13:42 EDT 2013

apt-get install qemu-sysem

Got this error:
tom@zoo:~$ qemu-system-arm -cpu cortex-m4 -nographic -monitor null -serial null -semihosting
qemu-system-arm: symbol lookup error: qemu-system-arm: undefined symbol: libusb_get_port_numbers


Probably due to this.  Removing..

tom@zoo:/usr/local/lib$ ls -al *usb*
lrwxrwxrwx 1 root root 76 Aug 11  2012 libmchpusb-1.0.so -> /opt/xc/microchip/mplabx/mplab_ide/mplablibs/modules/lib/libusb-1.0.so.0.0.0
lrwxrwxrwx 1 root root 17 May 21  2012 libusb-1.0.so.0 -> libmchpusb-1.0.so


Looks like cortex-m4 is not supported.  Works with cortex-m3 though.
Next is memory regions:

$ qemu-system-arm -cpu cortex-m3 -nographic -monitor null -serial null -semihosting -kernel console.axf -gdb tcp::1234

qemu: fatal: Trying to execute code outside RAM or ROM at 0x20000100

R00=20000100 R01=20000100 R02=ffffffff R03=00000000
R04=01000078 R05=00000000 R06=00000000 R07=00000000
R08=00000000 R09=00000000 R10=00000000 R11=00000000
R12=00000000 R13=200000e8 R14=0000037f R15=20000100
PSR=60000153 -ZC- A svc32
FPSCR: 00000000
Aborted

My guess is that it just has 128MB RAM at 0.  So to make this work, it
needs an elf that starts at 0?

So yes, that works, but apparently a simple .bin also works.



[1] http://dr.barik.net/kb/Assembly
[2] http://balau82.wordpress.com/2010/11/04/qemu-arm-semihosting/
[3] http://cgi.cs.indiana.edu/~geobrown/stm32/Main/Simulation


Entry: gdb trickery
Date: Sun Sep 15 18:54:50 EDT 2013

- parsing gdb data structures (OK)

- uploading code to ram (OK, arbitrary bytes)

- set temp breakpoint + run



Entry: State machine transformer
Date: Sat Sep 28 09:17:49 EDT 2013

The basic tasks:
  - environment capture for all yield points.
  - liveness analysis: does life-time cross yield points?

How much of this can be done with abstract interpretation?  Probably a
lot.  The interesting part is going to be how to do loops.

Analysis phases:
 - identify all variables (e.g. flatten)
 - identify all control paths

It doesn't fit in the standard rai template since it needs to capture
variable bindings.  Or does it?  Let's just give it a try.


It seems that this is really not so hard to do once the right
representation has been found.  What about avoiding control structures
in a first iteration and just concentrating on the idea of
continuation?

The existing SSA transformer can be used to build nested environments.
However, it's not really in an abstract reusable form, and it doesn't
directly abstract `let' forms, only as side effects..

It might be best to solve the problem in isolation first: build a
minimalistic scheme interpreter / compiler.

A simple example program: with 
- named let
- ordinary let*
- primitive invocation
- yield
- tail call

without:
- non-tail calls

(let next ((a 0))
  (let* ((a (inc a)))
    (yield a)
    (next a)))


It seems best to focus on let* instead of let, as it allows sequential
operation, which maps better to low-level code.

Named let is a bit annoying, but it's the only way to make loops
without explicit loop statements and explicit lambdas.  The language
is not supposed to be higher-order.


Interesting is that `yield' is the only non-tail position call in a
body.  ( let* rhs could have a proper non-tail call, which we ignore
for now )

From this it might make sense to make `yield' into function semantics,
i.e. always returning a value.  This leads to the program:

(define program
  '(let next ((a 0))
     (let* ((a (inc a))
            (_ (yield a)))
       (next a))))

Where we currently ignore yield's rv.


Now, a compilation would involve walking the tree and splitting each
yield into:

- what came before
-> treat yield as the inner expression / break off

- what comes after
-> reconstruct the environment = main problem


So this is the same as "representing the continuation".  The context
needs to be restored.   This includes control context.

Waiting for that flash to happen... 
Where is the difficulty?
Not thinking properly about the control structures.
Reconstructing the environment is easy.
The difficulty is in implementing the "variable update" behind the tail-recursive call.

So what about doing this all in a dumb way:

* rename each variable to a unique name and store them in a flat name
space.  optimize later for accessibility

* implement next in terms of set! and goto

This seems really simple and solves the whole problem.  The rest is
optimization.

